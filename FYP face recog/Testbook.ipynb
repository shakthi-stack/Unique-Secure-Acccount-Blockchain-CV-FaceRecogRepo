{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e82dbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa00fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ed7d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test1', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8c8178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FYP face recog', 'FYP-P1', 'input', 'MLDM', 'NCP', 'NCP-Project', 'NLP', 'PDC', 'SICP', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4decacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../train\"):\n",
    "    os.mkdir(\"../train\")\n",
    "if not os.path.exists(\"../train/A\"):\n",
    "    os.mkdir(\"../train/A\")\n",
    "if not os.path.exists(\"../train/B\"):\n",
    "    os.mkdir(\"../train/B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63bb1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19a6361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 833.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(\"../input/train\")):\n",
    "#     print(i)\n",
    "    if i.split(\".\")[0] == \"A\":\n",
    "        shutil.copy2(os.path.join(\"../input/train\",i),os.path.join(\"../train/A\",i))\n",
    "    elif i.split(\".\")[0] == \"B\":\n",
    "        shutil.copy2(os.path.join(\"../input/train\",i),os.path.join(\"../train/B\",i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d4c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../test\"):\n",
    "    os.mkdir(\"../test\")\n",
    "if not os.path.exists(\"../test/A\"):\n",
    "    os.mkdir(\"../test/A\")\n",
    "if not os.path.exists(\"../test/B\"):\n",
    "    os.mkdir(\"../test/B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b18fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ac0fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a125aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trdata = ImageDataGenerator()\n",
    "traindata = trdata.flow_from_directory(directory=\"../train\",target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "485090a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "tsdata = ImageDataGenerator()\n",
    "testdata = tsdata.flow_from_directory(directory=\"../test\", target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb90beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c5b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggmodel = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d9263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db48246e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x0000018A943D8B20>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9472B400>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9472BEB0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000018A9472BBB0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A948AC400>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A948AC130>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000018A948AC8B0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A948B97C0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9BBF14F0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A948B9700>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000018A9BBF14C0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9BBFAEB0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9BBFAD60>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9BC01310>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000018A948B4100>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9BC0BE50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9BC05A90>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000018A9BC12EB0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000018A9BC0BE20>\n",
      "<keras.layers.core.Flatten object at 0x0000018A9BC14AC0>\n",
      "<keras.layers.core.Dense object at 0x0000018A9BC058B0>\n",
      "<keras.layers.core.Dense object at 0x0000018A9BC1E490>\n",
      "<keras.layers.core.Dense object at 0x0000018A9BC24280>\n"
     ]
    }
   ],
   "source": [
    "for layers in (vggmodel.layers):\n",
    "    print(layers)\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc680837",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= vggmodel.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b83efc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4096) dtype=float32 (created by layer 'fc2')>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5420007",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(2, activation=\"softmax\")(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c101fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = Model(inputs = vggmodel.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7700d332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakt\\anaconda3\\envs\\vggfacemodel\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84a5bd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adba4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a8ec468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FYP face recog',\n",
       " 'FYP-P1',\n",
       " 'input',\n",
       " 'MLDM',\n",
       " 'NCP',\n",
       " 'NCP-Project',\n",
       " 'NLP',\n",
       " 'PDC',\n",
       " 'SICP',\n",
       " 'test',\n",
       " 'train']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67341900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=40, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e693a6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakt\\anaconda3\\envs\\vggfacemodel\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/2 [==============>...............] - ETA: 4:33 - loss: 1.8240 - accuracy: 0.3043WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "2/2 [==============================] - 276s 2s/step - loss: 1.8240 - accuracy: 0.3043 - val_loss: 1.5609 - val_accuracy: 0.2500\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    }
   ],
   "source": [
    "hist = model_final.fit_generator(generator= traindata, steps_per_epoch= 2, epochs= 5, validation_data= testdata, validation_steps=1, callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab49dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save_weights(\"vgg16_1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97b866b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shakthi.jpg\n",
      "[[0.34123662 0.6587634 ]]\n",
      "shakthi2.jpg\n",
      "[[0.909077   0.09092304]]\n",
      "sk.jpg\n",
      "[[0.03056837 0.9694316 ]]\n",
      "skandan.jpg\n",
      "[[0.931395   0.06860507]]\n",
      "someguy.jpg\n",
      "[[0.9123335  0.08766655]]\n"
     ]
    }
   ],
   "source": [
    "for e,i in enumerate(os.listdir(\"../input/test1\")):\n",
    "    print(i)\n",
    "    output=[]\n",
    "    img = image.load_img(os.path.join(\"../input/test1\",i),target_size=(224,224))\n",
    "    img = np.asarray(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    output = model_final.predict(img)\n",
    "    print(output)\n",
    "#     if output[0][0] > output[0][1]:\n",
    "#         print(\"A\")\n",
    "# #         df[\"id\"][e]=i\n",
    "# #         df[\"label\"][e]=\"cat\"\n",
    "#     else:\n",
    "#         print(\"B\")\n",
    "# #         df[\"id\"][e]=i\n",
    "# #         df[\"label\"][e]=\"dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb23a148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
